---
title: "Getting and processing data from WoS"
output: html_document
date: "2022-10-25"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

```{r}
library(sf)
library(rnaturalearth)
library(bibliometrix)
library(vegan)
```


### Querries in Web of Science

The first part consists in submit a query in Web of Science (WoS), selecting a sample from WoS with specific characteristics:

1.  Top 1000 highest cited paper for LA authors

2.  From the previous articles select a sub-sample containing only articles in top ecology journals

3.  Select single author papers from each region (LA, US and Canada, Europe and Asia)

4.  For each paper download a sample from all the citations these single author papers received

### Selecting regions based on World Bank classification

```{r}
countries <- ne_countries(scale = "medium", returnclass = "sf")
names_LA <- subset(countries, region_wb == "Latin America & Caribbean")$admin
names_NA <- subset(countries, region_wb == "North America")$admin
names_NA <- c(names_NA, "USA", "Usa", "United States")
names_EU <- subset(countries, region_wb == "Europe & Central Asia")$admin
names_EU <- c(names_EU, "England", "Scotland", "Wales", "UK")
names_MidleEastAfrica <- subset(countries, region_wb == "Middle East & North Africa")$admin
names_EastAsia <- subset(countries, region_wb == "East Asia & Pacific")$admin
names_SouthAsia <- subset(countries, region_wb == "South Asia")$admin
names_SubSahara <- subset(countries, region_wb == "Sub-Saharan Africa")$admin

```

Now I create the queries which will be submitted to WoS. First I build a general string following the format of queries for WoS. To do so I 
    subset the journals in which I want to perform my search and then glue them with the boolean characters and countries of 
    each region (accordinglyWorld Bank classification). In order to change the journal subset in which the query will be performed just change the `journal_sub` vector with different journal names. The journal names must be all upper case letters.

```{r queries_journal}
library(glue)

journal_sub <- c("NATURE ECOLOGY EVOLUTION" , "TRENDS IN ECOLOGY EVOLUTION" , "ECOLOGY LETTERS" , "METHODS IN ECOLOGY AND EVOLUTION" , "ECOLOGICAL APPLICATIONS" , "GLOBAL ECOLOGY AND BIOGEOGRAPHY" , "JOURNAL OF APPLIED ECOLOGY" , "JOURNAL OF ANIMAL ECOLOGY" , "BEHAVIORAL ECOLOGY" , "GLOBAL CHANGE BIOLOGY" , "FUNCTIONAL ECOLOGY" , "ECOSYSTEMS" , "ECOSPHERE" , "MOLECULAR ECOLOGY" , "ECOGRAPHY" , "APPLIED VEGETATION SCIENCE" , "ECOLOGY" , "BIODIVERSITY AND CONSERVATION" , "ECOLOGICAL MODELLING" , "MICROBIAL ECOLOGY" , "BIOLOGICAL CONSERVATION" , "JOURNAL OF BIOGEOGRAPHY" , "OECOLOGIA" , "RESTORATION ECOLOGY" , "JOURNAL OF VEGETATION SCIENCE" , "OIKOS" , "LANDSCAPE ECOLOGY" , "GLOBAL ECOLOGY AND CONSERVATION" , "FRESHWATER BIOLOGY" , "ANIMAL CONSERVATION" , "CONSERVATION BIOLOGY" , "JOURNAL OF ECOLOGY" , "DIVERSITY AND DISTRIBUTIONS") # valid for all searches

journal_query <- glue::glue('(SO == ("{(v)}"))', v = glue_collapse(journal_sub, '" OR "')) # general journal query pattern

```

With journal query pattern created I can build the whole query by gluing country and journal names. Each quey correspond to a defined region. We used, [World Bank regions](https://data.worldbank.org/country) to classify the countries. We also selected **Ecology** as the Web of Science category to perform the search (WC tag). For a complete list of tags see [Web of Science Core Collection help section](https://images.webofknowledge.com/images/help/WOS/hs_wos_fieldtags.html) 

```{r glueJouCont}
  
query_LA <- glue("WC =", "Ecology ", " AND ", " CU = (", glue::glue_collapse(names_LA,  sep = ' OR '), ") AND ", journal_query)
query_NA <- glue("WC =", "Ecology ", " AND ", " CU = (", glue::glue_collapse(names_NA,  sep = ' OR '), ") AND ", journal_query)
query_EU <- glue("WC =", "Ecology ", " AND ", " CU = (", glue::glue_collapse(names_EU,  sep = ' OR '), ") AND ", journal_query)
query_MidleEastAfrica <- glue("WC =", "Ecology ", " AND ", " CU = (", glue::glue_collapse(names_MidleEastAfrica,  sep = ' OR '), ") AND ", journal_query)
query_EastAsia <- glue("WC =", "Ecology ", " AND ", " CU = (", glue::glue_collapse(names_EastAsia,  sep = ' OR '), ") AND ", journal_query)
query_SouthAsia <- glue("WC =", "Ecology ", " AND ", " CU = (", glue::glue_collapse(names_SouthAsia,  sep = ' OR '), ") AND ", journal_query)
query_SubSahara <- glue("WC =", "Ecology ", " AND ", " CU = (", glue::glue_collapse(names_SubSahara,  sep = ' OR '), ") AND ", journal_query)

```

To replicate the same searches in WoS you only need to run one of the queries, copy the string vector printed in your console and paste it on search field in WoS. The search must be performed using *Web of Science Core collection* in the field **advanced search**. 

I ordered the search by the number of citation, with the most cited articles showing first. This is an important step since I used only the top cited articles of each region in downstream analysis.

The document downloaded to be used in downstream analysis must be the one under the name **Download plain text file format**. This is important since the plain text file format is the format used in Bibliometrix package.

### Processing queries

We are gonna need some libraries to process the results from queries


```{r libs}

library(here)
library(dplyr)
library(tidyverse)
library(magrittr)
```

The query was downloaded from WoS as a plain text. I downloaded the full record plain text file. Each file with query results are in the 
    format `REGION_top1000.txt`. All can be found in `data/raw` folder of this repository.

Now I can read the data and convert it to Bibliometrix format. I performed the conversions for each region.
    
#### LA processing

```{r}
files <- here::here("data", "raw", "LA_top1000.txt")
M <- convert2df(file = files, dbsource = 'wos', format = "plaintext")
results_LA <- biblioAnalysis(M, sep = ";")
M_single_LA <- M[which(unlist(lapply(strsplit(x = M$AU, split = ";"), function(x) length(x))) == 1), ]
```

We selected only single author paper (`M_single_LA`) to avoid confounding factors, e.g collaborations, number of co-authors, correspondence author from region  nor corresponding to the search etc. Since the query returns some single author papers from authors in which the affiliation does not correspond to a LA countries I applied a second filter to detect only author's affiliations containing at least one Latin American country. Sometimes the author has more than one affiliation. In these cases, if at least one of the affiliation correspond to a institution in a LA country this work is considered for further analysis.

```{r filter_la1}

la_names <- toupper(names_LA) # Latin American country names
s_paper_la <- unique(unlist(lapply(la_names, function(x) grep(x, M_single_LA$C1)))) # filtering by single author paper from LA 
M_single_LA <- M_single_LA[s_paper_la, ] # unique single article papers from LA
q_top_LA <- glue::glue("UT = (", glue::glue_collapse(M_single_LA$UT,  sep = ' OR '), ")")

```

We used the identifier obtained in the last step to submit a query in WoS. I re-ordered the results from the query to show
    the most cited papers that cited the top single author papers. Again, I downloaded plain text files for the first 5000 articles
    citing the top 1000 single author articles from LA. These articles can be found in `data/processed/LA_citing_articles` folder.


Here I read the 5000 articles that cited LA papers and accessed the countries in which the citations comes from (corresponding author countries). this information was stored in a data frame containing the absolute number of citations per country and the proportional value

```{r}
files <- here::here("data", "processed", "LA_citing_articles", c("01_citing_LA.txt", "02_citing_LA.txt", "03_citing_LA.txt",  "04_citing_LA.txt",  "05_citing_LA.txt"))
M_citations_la <- convert2df(file = files, dbsource = 'wos', format = "plaintext") # converting articles to bibliometrix format
results_citation_la <- biblioAnalysis(M_citations_la, sep = ";")
countries_cite_LA <- results_citation_la$Countries[order(results_citation_la$Countries, decreasing = TRUE)]
prop_countries_cite_LA <- (countries_cite_LA)/sum(countries_cite_LA)
tab_citation_LA <- data.frame(countries = names(countries_cite_LA), 
                              LA.citation = as.vector(countries_cite_LA), 
                              LA.citation.prop = as.vector(prop_countries_cite_LA))
```

#### Write and submit a query for US and Canada papers

Query used to search 1000 most cited papers in US and Canada

The query was downloaded from WoS as a plain text. I downloaded the full record plain text file. This is the file named as `US_CAN_top1000.txt` in `data/raw` folder of this repository

```{r}
files <- here::here("data", "raw", "USA_CAN_top1000.txt")
M <- convert2df(file = files, dbsource = 'wos', format = "plaintext")
results <- biblioAnalysis(M, sep = ";")
M_single_USA_CAN <- M[which(unlist(lapply(strsplit(x = M$AU, split = ";"), function(x) length(x))) == 1), ] # single author papers for USA and CAN

```

Since the query returns some single author papers from authors in which the affiliation does not correspond to a US or Can , I applied a second filter to select only author's affiliations that contains at least one of Canada or US affiliation in author's information

```{r filter_la1}
usa_can_names <- toupper(names_NA) # Latin American country names
s_paper_can_usa <- unique(unlist(lapply(usa_can_names, function(x) grep(x, M_single_USA_CAN$C1)))) # filtering by single author paper from LA 
M_single_USA_CAN <- M_single_USA_CAN[s_paper_can_usa, ] # unique single article papers from LA
q_top_USA_CAN <- glue::glue("UT = (", glue::glue_collapse(M_single_USA_CAN$UT,  sep = ' OR '), ")")
```

Most 10000 recent citations from top 235 single author papers from. These citation articles were extracted from WoS using the code above, we simply copied and paste the identifiers above in the browser using the web application of WoS to perform the search. This is the same procedure I performed above for LA region

```{r}
files <- here::here("data", "processed", "USA_CAN_citing_articles", c("01_citing_USA_CAN.txt", "02_citing_USA_CAN.txt", "03_citing_USA_CAN.txt", "04_citing_USA_CAN.txt", "05_citing_USA_CAN.txt", "06_citing_USA_CAN.txt", "07_citing_USA_CAN.txt", "08_citing_USA_CAN.txt", "09_citing_USA_CAN.txt", "10_citing_USA_CAN.txt"))
M_citations_usa_can <- convert2df(file = files, dbsource = 'wos', format = "plaintext") # this will take a few minutes
results_citation_usa_can <- biblioAnalysis(M_citations_usa_can, sep = ";")
countries_cite_USA <- results_citation_usa_can$Countries[order(results_citation_usa_can$Countries, decreasing = TRUE)]
prop_countries_cite_USA <- (countries_cite_USA)/sum(countries_cite_USA)
tab_citation_USA <- data.frame(countries = names(countries_cite_USA), 
                              usa.citation = as.vector(countries_cite_USA), 
                              usa.citation.prop = as.vector(prop_countries_cite_USA))
```
#### Querryng papers in europe

Using the query for EU countries and reading the top 1000 most cited papers from that region


```{r}
files <- here::here("data", "raw", "EU_top1000.txt")
M <- convert2df(file = files, dbsource = 'wos', format = "plaintext")
results_EU <- biblioAnalysis(M, sep = ";")
M_single_EU <- M[which(unlist(lapply(strsplit(x = M$AU, split = ";"), function(x) length(x))) == 1), ]
```


Now selecting single author papers

```{r}
eu_names <- toupper(names_EU)
s_paper_eu <- unique(unlist(lapply(eu_names, function(x) grep(x, M_single_EU$C1)))) # filtering by single author paper from LA 
M_single_EU <- M_single_EU[s_paper_eu, ] # unique single article papers from LA
q_top_EU <- glue::glue("UT = (", glue::glue_collapse(M_single_EU$UT,  sep = ' OR '), ")") # querry for LA single-author paper 
```

We used the previous querry to find the single article authors in WoS and downloaded the information of the 10000 papers citing EU single author papers

```{r}
files <- here::here("data", "processed", "EU_citing_articles", c("01_citing_EU.txt", "02_citing_EU.txt", "03_citing_EU.txt", "04_citing_EU.txt", "05_citing_EU.txt", "06_citing_EU.txt", "07_citing_EU.txt", "08_citing_EU.txt", "09_citing_EU.txt", "10_citing_EU.txt"))
M_citations_EU <- convert2df(file = files, dbsource = 'wos', format = "plaintext") # this will take a few minutes
results_citation_EU <- biblioAnalysis(M_citations_EU, sep = ";")
countries_cite_EU <- results_citation_EU$Countries[order(results_citation_EU$Countries, decreasing = TRUE)]
prop_countries_cite_EU <- (countries_cite_EU)/sum(countries_cite_EU)
tab_citation_EU <- data.frame(countries = names(countries_cite_EU), 
                              eu.citation = as.vector(countries_cite_EU), 
                              eu.citation.prop = as.vector(prop_countries_cite_EU))
```

#### Queryng papers in Asian

```{r}

files <- here::here("data", "raw", "EastAsia_top1000.txt")
M <- convert2df(file = files, dbsource = 'wos', format = "plaintext")
results_EastAsia <- biblioAnalysis(M, sep = ";")
M_single_EastAsia <- M[which(unlist(lapply(strsplit(x = M$AU, split = ";"), function(x) length(x))) == 1), ]

```

Same procedure here. We extracted the top single author papers from East Asia region and obtained their ID to find the papers that cited these works

```{r}
eastasia_names <- toupper(names_EastAsia)
s_paper_eastasia <- unique(unlist(lapply(eastasia_names, function(x) grep(x, M_single_EastAsia$C1)))) # filtering by single author paper from LA 
M_single_EastAsia <- M_single_EastAsia[s_paper_eastasia, ] # unique single article papers from LA
q_top_EastAsia <- glue::glue("UT = (", glue::glue_collapse(M_single_EastAsia$UT,  sep = ' OR '), ")") # querry for LA single-author paper 
```

Finally, I downloaded the information for 7000 studies that cited the top single author papers in East Asia

```{r}
files <- here::here("data", "processed", "EastAsia_citing_articles", c("01_citing_EastAsia.txt", "02_citing_EastAsia.txt", "03_citing_EastAsia.txt", "04_citing_EastAsia.txt", "05_citing_EastAsia.txt", "06_citing_EastAsia.txt", "07_citing_EastAsia.txt"))
M_citations_EastAsia <- convert2df(file = files, dbsource = 'wos', format = "plaintext") # this will take a few minutes
results_citation_EastAsia <- biblioAnalysis(M_citations_EastAsia, sep = ";")
countries_cite_EastAsia <- results_citation_EastAsia$Countries[order(results_citation_EastAsia$Countries, decreasing = TRUE)]
prop_countries_cite_EastAsia <- (countries_cite_EastAsia)/sum(countries_cite_EastAsia)
tab_citation_EastAsia <- data.frame(countries = names(countries_cite_EastAsia), 
                              EastAsia.citation = as.vector(countries_cite_EastAsia), 
                              EastAsia.citation.prop = as.vector(prop_countries_cite_EastAsia))
```

#### Queryng papers for Midle East Africa

```{r}

files <- here::here("data", "raw", "MiddleEastAfrica_top1000.txt")
M <- convert2df(file = files, dbsource = 'wos', format = "plaintext")
results_MiddleEastAfrica <- biblioAnalysis(M, sep = ";")
M_single_MiddleEastAfrica <- M[which(unlist(lapply(strsplit(x = M$AU, split = ";"), function(x) length(x))) == 1), ]

```

Now selecting single author papers

```{r}
midleafrica_names <- toupper(names_MidleEastAfrica)
s_paper_midleafrica <- unique(unlist(lapply(midleafrica_names, function(x) grep(x, M_single_MiddleEastAfrica$C1)))) # filtering by single author paper from Middle and east africa
M_single_MiddleEastAfrica <- M_single_MiddleEastAfrica[s_paper_midleafrica, ] # unique single article papers from LA
q_top_MiddleAfrica <- glue::glue("UT = (", glue::glue_collapse(M_single_MiddleEastAfrica$UT,  sep = ' OR '), ")") # query for LA single-author paper 
```

We used the previous query to find the single article authors in WoS and downloaded the information of the ~4000 papers citing East Middle Africa single author papers

```{r}
files <- here::here("data", "processed", "MiddleEastAfrica_citing_articles", c("01_citing_MAfrica.txt", "02_citing_MAfrica.txt", "03_citing_MAfrica.txt", "04_citing_MAfrica.txt"))
M_citations_MiddleAfrica <- convert2df(file = files, dbsource = 'wos', format = "plaintext") # this will take a few minutes
results_citation_MiddleAfrica <- biblioAnalysis(M_citations_MiddleAfrica, sep = ";")
countries_cite_MiddleAfrica <- results_citation_MiddleAfrica$Countries[order(results_citation_MiddleAfrica$Countries, decreasing = TRUE)]
prop_countries_cite_MiddleAfrica <- (countries_cite_MiddleAfrica)/sum(countries_cite_MiddleAfrica)
tab_citation_MiddleAfrica <- data.frame(countries = names(countries_cite_MiddleAfrica), 
                              middle.citation = as.vector(countries_cite_MiddleAfrica), 
                              eu.citation.prop = as.vector(prop_countries_cite_MiddleAfrica))
```

### Binding the tables and plotting the results

```{r}
tab_all_citation <- 
  tab_citation_USA %>% 
  right_join(tab_citation_LA, by = "countries") %>% 
  right_join(tab_citation_EU, by = "countries")  %>% 
  right_join(tab_citation_EastAsia, by = "countries") %>% 
  right_join(tab_citation_MiddleAfrica, by = "countries")
```

# Citation bias analysis 

```{r political_reg}
library(ggplot2)
library(vegan)

tab_all_citation$continent <- NA
tab_all_citation$countries <- str_to_title(tab_all_citation$countries)
tab_all_citation[tab_all_citation$countries %in% names_LA, "continent"] <- "Latin America"
tab_all_citation[tab_all_citation$countries %in% names_NA, "continent"] <- "USA and Can"
tab_all_citation[tab_all_citation$countries %in% names_EU, "continent"] <- "Europe"
tab_all_citation[tab_all_citation$countries %in% names_MidleEastAfrica, "continent"] <- "Middle East & Africa"
tab_all_citation[tab_all_citation$countries %in% names_EastAsia, "continent"] <- "East Asia"
tab_all_citation[tab_all_citation$countries %in% names_SouthAsia, "continent"] <- "South Asia"

# manually fixing some classifications
tab_all_citation[which(is.na(tab_all_citation$continent) == TRUE), "continent"] <- 
  c("Middle East & Africa", "Middle East & Africa", "East Asia", "Other", "Middle East & Africa", "Middle East & Africa", "Middle East & Africa", "Middle East & Africa", "Middle East & Africa", "Middle East & Africa", "Europe")

tab_all_citation[which(tab_all_citation$continent == "Malawi"), "continent"] <- "Middle East & Africa"


```
### citation bias

We used the Pielou evenness index to express the degree of citation bias. Lower values indicate that citation are more biased towards certain regions/countries. Higher values indicate that the citations are more evenly distributed throught different countries.

```{r}
H_usa <- 
diversity(tab_all_citation$usa.citation[!is.na(tab_all_citation$usa.citation)], index = "shannon")

H_la <- 
diversity(tab_all_citation$LA.citation[!is.na(tab_all_citation$LA.citation)], index = "shannon")

H_eu <- diversity(tab_all_citation$eu.citation[!is.na(tab_all_citation$eu.citation)], index = "shannon")

H_eastasia <- diversity(tab_all_citation$EastAsia.citation[!is.na(tab_all_citation$EastAsia.citation)], index = "shannon")


J_usa <- H_usa/log(length(tab_all_citation$usa.citation[!is.na(tab_all_citation$usa.citation)]))

J_la <- H_la/log(length(tab_all_citation$LA.citation[!is.na(tab_all_citation$LA.citation)]))

J_eu <- H_eu/log(length(tab_all_citation$eu.citation[!is.na(tab_all_citation$eu.citation)]))

J_east_asia <- H_eu/log(length(tab_all_citation$EastAsia.citation[!is.na(tab_all_citation$EastAsia.citation)]))


```

### plotting citation proportion

```{r plot}
library(cowplot)

usa_citation_plot <- 
ggplot(data = tab_all_citation, aes(x = continent, y = usa.citation.prop)) +
  geom_violin() +
  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = 0.5) +
  stat_summary(fun = "mean",
               geom = "crossbar", 
               width = 0.3,
               colour = "blue") +
  scale_y_continuous(limits = c(0, 1), trans = "sqrt") +
  ylab("Proportion citations USA-CAN") +
  xlab("") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1)) +
  annotate("text", x = 6, y = 1, 
           label = glue::glue("italic(J)=={round(J_usa, 3)}"), 
           parse = TRUE, size = 5)

la_citation_plot <- 
ggplot(data = tab_all_citation, aes(x = continent, y = LA.citation.prop)) +
  geom_violin() +
  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = 0.5) +
  stat_summary(fun = "mean",
               geom = "crossbar", 
               width = 0.3,
               colour = "blue") +
  ylab("Proportion citations LA") +
  xlab("") +
  scale_y_continuous(limits = c(0, 1), trans = "sqrt") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1)) +
  annotate("text", x = 6, y = 1, 
           label = glue::glue("italic(J)=={round(J_la, 3)}"), 
           parse = TRUE, size = 5)

eu_citation_plot <- 
  ggplot(data = tab_all_citation, aes(x = continent, y = eu.citation.prop)) +
    geom_violin() + 
  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = 0.5) +
  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = 0.5) +
  stat_summary(fun = "mean",
               geom = "crossbar", 
               width = 0.3,
               colour = "blue") +
  ylab("Proportion citations EU") +
  xlab("") +
  scale_y_continuous(limits = c(0, 1), trans = "sqrt") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1)) +
  annotate("text", x = 6, y = 1, 
           label = glue::glue("italic(J)=={round(J_eu, 3)}"), 
           parse = TRUE, size = 5)

eastasia_citation_plot <- 
  ggplot(data = tab_all_citation, aes(x = continent, y = EastAsia.citation.prop)) +
    geom_violin() + 
  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = 0.5) +
  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = 0.5) +
  stat_summary(fun = "mean",
               geom = "crossbar", 
               width = 0.3,
               colour = "blue") +
  ylab("Proportion citations East Asia") +
  xlab("") +
  scale_y_continuous(limits = c(0, 1), trans = "sqrt") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1)) +
  annotate("text", x = 6, y = 1, 
           label = glue::glue("italic(J)=={round(J_east_asia, 3)}"), 
           parse = TRUE, size = 5)


plot_all <- usa_citation_plot + la_citation_plot + eu_citation_plot + eastasia_citation_plot

```

Trying some different ways to present the data on citation bias. Barplots bellow

```{r}

tab_all_citation <- readRDS(here::here("data", "processed", "tab_all_citation.rds"))
tab_all_citation <- tab_all_citation[-which(tab_all_citation$continent == "Other"), ]
usa_citation_plot <- 
ggplot() +
  geom_bar(data = tab_all_citation, aes(x = continent, y = usa.citation.prop), position = "dodge", stat = "identity") +
  ylim(0, 0.5) +
  ylab("Proportion citations USA-CAN") +
  xlab("") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1), legend.position = "none")  +
  annotate("text", x = 5.7, y = 0.5, 
           label = glue::glue("italic(J)=={round(J_usa, 3)}"), 
           parse = TRUE, size = 5)
  
la_citation_plot <- 
ggplot() +
  geom_bar(data = tab_all_citation, aes(x = continent, y = LA.citation.prop), position = "dodge", stat = "identity") +
  ylim(0, 0.5) +
  ylab("Proportion citations LA") +
  xlab("") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1), legend.position = "none")  +
  annotate("text", x = 5, y = 0.5, 
           label = glue::glue("italic(J)=={round(J_la, 3)}"), 
           parse = TRUE, size = 5)

eu_citation_plot <- 
ggplot() +
  geom_bar(data = tab_all_citation, aes(x = continent, y = eu.citation.prop), position = "dodge", stat = "identity") +
  ylim(0, 0.5) +
  ylab("Proportion citations EU") +
  xlab("") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1), legend.position = "none")  +
  annotate("text", x = 5.7, y = 0.5, 
           label = glue::glue("italic(J)=={round(J_eu, 3)}"), 
           parse = TRUE, size = 5)

eastasia_citation_plot <- 
ggplot() +
  geom_bar(data = tab_all_citation, aes(x = continent, y = EastAsia.citation.prop), position = "dodge", stat = "identity") +
  ylim(0, 0.5) +
  ylab("Proportion citations East Asia") +
  xlab("") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1), legend.position = "none")  +
  annotate("text", x = 5, y = 0.5, 
           label = glue::glue("italic(J)=={round(J_east_asia, 3)}"), 
           parse = TRUE, size = 5)

plot_all <- usa_citation_plot + la_citation_plot + eu_citation_plot + eastasia_citation_plot

```



Saving plot that goes in the main text 

```{r}

ggsave(filename = here::here("output", "Fig1_citation_all.png"), 
       plot = plot_all, 
       width = 15, 
       height = 8, 
       dpi = 300)
```



Saving tables with all citation values and proportions

```{r}
saveRDS(object = tab_all_citation, file = here::here("data", "processed", "tab_all_citation.rds"))
```







