---
title: "Getting and processing data from WoS"
output: html_document
date: "2022-10-25"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

```{r}
library(sf)
library(rnaturalearth)
library(bibliometrix)
```


### Querries in Web of Science

The first part consists in submit a query in Web of Science (WoS), selecting a sample from WoS with specific characteristics:

1.  Top 1000 highest cited paper for LA authors

2.  From the previous articles select a sub-sample containing only articles in top ecology journals

3.  Select single author papers from each region (LA, US and Canada, Europe and Asia)

4.  For each paper download a sample from all the citations these single author papers received

### Selecting regions based on World Bank classification

```{r}
countries <- ne_countries(scale = "medium", returnclass = "sf")
names_LA <- subset(countries, region_wb == "Latin America & Caribbean")$admin
names_NA <- subset(countries, region_wb == "North America")$admin
names_NA <- c(names_NA, "USA", "Usa", "United States")
names_EU <- subset(countries, region_wb == "Europe & Central Asia")$admin
names_EU <- c(names_EU, "England", "Scotland", "Wales", "UK")
names_MidleEastAfrica <- subset(countries, region_wb == "Middle East & North Africa")$admin
names_EastAsia <- subset(countries, region_wb == "East Asia & Pacific")$admin
names_SouthAsia <- subset(countries, region_wb == "South Asia")$admin
names_SubSahara <- subset(countries, region_wb == "Sub-Saharan Africa")$admin

```

Now I create the queries which will be submitted to WoS. First I build a general string following the format of queries for WoS. To do so I 
    subset the journals in which I want to perform my search and then glue them with the boolean characters and countries of 
    each region (accordinglyWorld Bank classification). In case of wanting to change the journal subset the user only need to change the `journal_sub` vector with different journal names.

```{r queries_journal}
library(glue)

journal_sub <- c("NATURE ECOLOGY EVOLUTION" , "TRENDS IN ECOLOGY EVOLUTION" , "ECOLOGY LETTERS" , "METHODS IN ECOLOGY AND EVOLUTION" , "ECOLOGICAL APPLICATIONS" , "GLOBAL ECOLOGY AND BIOGEOGRAPHY" , "JOURNAL OF APPLIED ECOLOGY" , "JOURNAL OF ANIMAL ECOLOGY" , "BEHAVIORAL ECOLOGY" , "GLOBAL CHANGE BIOLOGY" , "FUNCTIONAL ECOLOGY" , "ECOSYSTEMS" , "ECOSPHERE" , "MOLECULAR ECOLOGY" , "ECOGRAPHY" , "APPLIED VEGETATION SCIENCE" , "ECOLOGY" , "BIODIVERSITY AND CONSERVATION" , "ECOLOGICAL MODELLING" , "MICROBIAL ECOLOGY" , "BIOLOGICAL CONSERVATION" , "JOURNAL OF BIOGEOGRAPHY" , "OECOLOGIA" , "RESTORATION ECOLOGY" , "JOURNAL OF VEGETATION SCIENCE" , "OIKOS" , "LANDSCAPE ECOLOGY" , "GLOBAL ECOLOGY AND CONSERVATION" , "FRESHWATER BIOLOGY" , "ANIMAL CONSERVATION" , "CONSERVATION BIOLOGY" , "JOURNAL OF ECOLOGY" , "DIVERSITY AND DISTRIBUTIONS") # valid for all searches

journal_query <- glue::glue('(SO == ("{(v)}"))', v = glue_collapse(journal_sub, '" OR "')) # general journal query pattern

```

With journal query pattern create then I can build the whole query by gluing country and journal

```{r}
  
query_LA <- glue("WC =", "Ecology ", " AND ", " CU = (", glue::glue_collapse(names_LA,  sep = ' OR '), ") AND ", journal_query)
query_NA <- glue("WC =", "Ecology ", " AND ", " CU = (", glue::glue_collapse(names_NA,  sep = ' OR '), ") AND ", journal_query)
query_EU <- glue("WC =", "Ecology ", " AND ", " CU = (", glue::glue_collapse(names_EU,  sep = ' OR '), ") AND ", journal_query)
query_MidleEastAfrica <- glue("WC =", "Ecology ", " AND ", " CU = (", glue::glue_collapse(names_MidleEastAfrica,  sep = ' OR '), ") AND ", journal_query)
query_EastAsia <- glue("WC =", "Ecology ", " AND ", " CU = (", glue::glue_collapse(names_EastAsia,  sep = ' OR '), ") AND ", journal_query)
query_SouthAsia <- glue("WC =", "Ecology ", " AND ", " CU = (", glue::glue_collapse(names_SouthAsia,  sep = ' OR '), ") AND ", journal_query)
query_SubSahara <- glue("WC =", "Ecology ", " AND ", " CU = (", glue::glue_collapse(names_SubSahara,  sep = ' OR '), ") AND ", journal_query)

```

To replicate the same searches in WoS you only need to run one of the queries, copy the string vector printed in your console and paste it on search field in WoS. The search must be performed using *Web of Science Core collection*. *Download plain text file format*

### Processing queries


We are gonna need some libraries to process the results from queries


```{r libs}

library(here)
library(dplyr)
library(tidyverse)
library(magrittr)
```

The query was downloaded from WoS as a plain text. I downloaded the full record plain text file. Each file with query results are in the 
    format `REGION_top1000.txt`. All can be found in `data/raw` folder of this repository. I read the data and converted it to bibliometrix format. 
    
#### LA processing

```{r}
files <- here::here("data", "raw", "LA_top1000.txt")
M <- convert2df(file = files, dbsource = 'wos', format = "plaintext")
results_LA <- biblioAnalysis(M, sep = ";")
M_single_LA <- M[which(unlist(lapply(strsplit(x = M$AU, split = ";"), function(x) length(x))) == 1), ]
```

We selected only single author paper to avoid confounding factors, e.g colaborations, number of co-authors, correspondence author from region  nor corresponding to the search etc. Since the query returns some single author papers from authors in which the affiliation does not correspond to a LA countries I applied a second filter to detect only author's affiliations containing at least one Latin American country

```{r filter_la1}

la_names <- toupper(names_LA) # Latin American country names
s_paper_la <- unique(unlist(lapply(la_names, function(x) grep(x, M_single_LA$C1)))) # filtering by single author paper from LA 
M_single_LA <- M_single_LA[s_paper_la, ] # unique single article papers from LA
q_top_LA <- glue::glue("UT = (", glue::glue_collapse(M_single_LA$UT,  sep = ' OR '), ")")

```

We used the identifier obtained in the last step to submit a query in WoS. I re-ordered the results from the query to show
    first the most cited papers that cited the single author papers. Again, I downloaded plain text files for the first 5000 articles
    citing the top 1000 single author articles from LA


Reading the 5000 articles that cited LA papers

```{r}
files <- here::here("data", "processed", "LA_citing_articles", c("01_citing_LA.txt", "02_citing_LA.txt", "03_citing_LA.txt",  "04_citing_LA.txt",  "05_citing_LA.txt"))
M_citations_la <- convert2df(file = files, dbsource = 'wos', format = "plaintext") # converting articles to bibliometrix format
results_citation_la <- biblioAnalysis(M_citations_la, sep = ";")
countries_cite_LA <- results_citation_la$Countries[order(results_citation_la$Countries, decreasing = TRUE)]
prop_countries_cite_LA <- (countries_cite_LA)/sum(countries_cite_LA)
tab_citation_LA <- data.frame(countries = names(countries_cite_LA), 
                              LA.citation = as.vector(countries_cite_LA), 
                              LA.citation.prop = as.vector(prop_countries_cite_LA))
```

#### Write and submit a query for US and Canada papers

Query used to search 1000 most cited papers in US and Canada

The query was downloaded from WoS as a plain text. I downloaded the full record plain text file. This is the file named as `US_CAN_top1000.txt` in `data/raw` folder of this repository

```{r}
files <- here::here("data", "raw", "USA_CAN_top1000.txt")
M <- convert2df(file = files, dbsource = 'wos', format = "plaintext")
results <- biblioAnalysis(M, sep = ";")
M_single_USA_CAN <- M[which(unlist(lapply(strsplit(x = M$AU, split = ";"), function(x) length(x))) == 1), ] # single author papers for USA and CAN

```

Since the query returns some single author papers from authors in which the affiliation does not correspond to a US or Can , I applied a second filter to select only author's affiliations that contains at least one of Canada or US affiliation in author's information

```{r filter_la1}
usa_can_names <- toupper(names_NA) # Latin American country names
s_paper_can_usa <- unique(unlist(lapply(usa_can_names, function(x) grep(x, M_single_USA_CAN$C1)))) # filtering by single author paper from LA 
M_single_USA_CAN <- M_single_USA_CAN[s_paper_can_usa, ] # unique single article papers from LA
q_top_USA_CAN <- glue::glue("UT = (", glue::glue_collapse(M_single_USA_CAN$UT,  sep = ' OR '), ")")
```

Most 10000 recent citations from top 235 single author papers from. These citation articles were extracted from WoS using the code above, we simply copied and paste the identifiers above in the browser using the web application of WoS to perform the search

```{r}
files <- here::here("data", "processed", "USA_CAN_citing_articles", c("01_citing_USA_CAN.txt", "02_citing_USA_CAN.txt", "03_citing_USA_CAN.txt", "04_citing_USA_CAN.txt", "05_citing_USA_CAN.txt", "06_citing_USA_CAN.txt", "07_citing_USA_CAN.txt", "08_citing_USA_CAN.txt", "09_citing_USA_CAN.txt", "10_citing_USA_CAN.txt"))
M_citations_usa_can <- convert2df(file = files, dbsource = 'wos', format = "plaintext") # this will take a few minutes
results_citation_usa_can <- biblioAnalysis(M_citations_usa_can, sep = ";")
countries_cite_USA <- results_citation_usa_can$Countries[order(results_citation_usa_can$Countries, decreasing = TRUE)]
prop_countries_cite_USA <- (countries_cite_USA)/sum(countries_cite_USA)
tab_citation_USA <- data.frame(countries = names(countries_cite_USA), 
                              usa.citation = as.vector(countries_cite_USA), 
                              usa.citation.prop = as.vector(prop_countries_cite_USA))
```
#### Querryng papers in europe

Using the query for EU countries


```{r}
files <- here::here("data", "raw", "EU_top1000.txt")
M <- convert2df(file = files, dbsource = 'wos', format = "plaintext")
results_EU <- biblioAnalysis(M, sep = ";")
M_single_EU <- M[which(unlist(lapply(strsplit(x = M$AU, split = ";"), function(x) length(x))) == 1), ]
```


Now selecting single author papers

```{r}
eu_names <- toupper(names_EU)
s_paper_eu <- unique(unlist(lapply(eu_names, function(x) grep(x, M_single_EU$C1)))) # filtering by single author paper from LA 
M_single_EU <- M_single_EU[s_paper_eu, ] # unique single article papers from LA
q_top_EU <- glue::glue("UT = (", glue::glue_collapse(M_single_EU$UT,  sep = ' OR '), ")") # querry for LA single-author paper 
```
We used the previous querry to find the single article authors in WoS

```{r}
files <- here::here("data", "processed", "EU_citing_articles", c("01_citing_EU.txt", "02_citing_EU.txt", "03_citing_EU.txt", "04_citing_EU.txt", "05_citing_EU.txt", "06_citing_EU.txt", "07_citing_EU.txt", "08_citing_EU.txt", "09_citing_EU.txt", "10_citing_EU.txt"))
M_citations_EU <- convert2df(file = files, dbsource = 'wos', format = "plaintext") # this will take a few minutes
results_citation_EU <- biblioAnalysis(M_citations_EU, sep = ";")
countries_cite_EU <- results_citation_EU$Countries[order(results_citation_EU$Countries, decreasing = TRUE)]
prop_countries_cite_EU <- (countries_cite_EU)/sum(countries_cite_EU)
tab_citation_EU <- data.frame(countries = names(countries_cite_EU), 
                              eu.citation = as.vector(countries_cite_EU), 
                              eu.citation.prop = as.vector(prop_countries_cite_EU))
```

#### Queryng papers in Asian

```{r}

files <- here::here("data", "raw", "EastAsia_top1000.txt")
M <- convert2df(file = files, dbsource = 'wos', format = "plaintext")
results_EastAsia <- biblioAnalysis(M, sep = ";")
M_single_EastAsia <- M[which(unlist(lapply(strsplit(x = M$AU, split = ";"), function(x) length(x))) == 1), ]

```



```{r}
eastasia_names <- toupper(names_EastAsia)
s_paper_eastasia <- unique(unlist(lapply(eastasia_names, function(x) grep(x, M_single_EastAsia$C1)))) # filtering by single author paper from LA 
M_single_EastAsia <- M_single_EastAsia[s_paper_eastasia, ] # unique single article papers from LA
q_top_EastAsia <- glue::glue("UT = (", glue::glue_collapse(M_single_EastAsia$UT,  sep = ' OR '), ")") # querry for LA single-author paper 
```

```{r}
files <- here::here("data", "processed", "EastAsia_citing_articles", c("01_citing_EastAsia.txt", "02_citing_EastAsia.txt", "03_citing_EastAsia.txt", "04_citing_EastAsia.txt", "05_citing_EastAsia.txt", "06_citing_EastAsia.txt", "07_citing_EastAsia.txt"))
M_citations_EastAsia <- convert2df(file = files, dbsource = 'wos', format = "plaintext") # this will take a few minutes
results_citation_EastAsia <- biblioAnalysis(M_citations_EastAsia, sep = ";")
countries_cite_EastAsia <- results_citation_EastAsia$Countries[order(results_citation_EastAsia$Countries, decreasing = TRUE)]
prop_countries_cite_EastAsia <- (countries_cite_EastAsia)/sum(countries_cite_EastAsia)
tab_citation_EastAsia <- data.frame(countries = names(countries_cite_EastAsia), 
                              EastAsia.citation = as.vector(countries_cite_EastAsia), 
                              EastAsia.citation.prop = as.vector(prop_countries_cite_EastAsia))
```



### Binding the tables and plotting the results

```{r}
tab_all_citation <- 
  tab_citation_USA %>% 
  right_join(tab_citation_LA, by = "countries") %>% 
  right_join(tab_citation_EU, by = "countries")  %>% 
  right_join(tab_citation_EastAsia, by = "countries")
```


```{r political_reg}
library(ggplot2)
library(rnaturalearthdata)


tab_all_citation$continent <- NA
tab_all_citation$countries <- str_to_title(tab_all_citation$countries)
tab_all_citation[tab_all_citation$countries %in% names_LA, "continent"] <- "Latin America"
tab_all_citation[tab_all_citation$countries %in% names_NA, "continent"] <- "USA and Can"
tab_all_citation[tab_all_citation$countries %in% names_EU, "continent"] <- "Europe"
tab_all_citation[tab_all_citation$countries %in% names_MidleEastAfrica, "continent"] <- "Middle East & Africa"
tab_all_citation[tab_all_citation$countries %in% names_EastAsia, "continent"] <- "East Asia"
tab_all_citation[tab_all_citation$countries %in% names_SouthAsia, "continent"] <- "South Asia"

# manually fixing some classifications
tab_all_citation[which(is.na(tab_all_citation$continent) == TRUE), "continent"] <- 
  c("Middle East & Africa", "Middle East & Africa", "East Asia", "Other", "Middle East & Africa", "Middle East & Africa", "Middle East & Africa", "Middle East & Africa", "Middle East & Africa", "Middle East & Africa", "Europe")

tab_all_citation[which(tab_all_citation$continent == "Malawi"), "continent"] <- "Middle East & Africa"


```


Calculating all Pielo evenness values
```{r}
H_usa <- 
diversity(tab_all_citation$usa.citation[!is.na(tab_all_citation$usa.citation)], index = "shannon")

H_la <- 
diversity(tab_all_citation$LA.citation[!is.na(tab_all_citation$LA.citation)], index = "shannon")

H_eu <- diversity(tab_all_citation$eu.citation[!is.na(tab_all_citation$eu.citation)], index = "shannon")

H_eastasia <- diversity(tab_all_citation$EastAsia.citation[!is.na(tab_all_citation$EastAsia.citation)], index = "shannon")


J_usa <- H_usa/log(length(tab_all_citation$usa.citation[!is.na(tab_all_citation$usa.citation)]))

J_la <- H_la/log(length(tab_all_citation$LA.citation[!is.na(tab_all_citation$LA.citation)]))

J_eu <- H_eu/log(length(tab_all_citation$eu.citation[!is.na(tab_all_citation$eu.citation)]))

J_east_asia <- H_eu/log(length(tab_all_citation$EastAsia.citation[!is.na(tab_all_citation$EastAsia.citation)]))


```



```{r plot}
library(cowplot)
library(vegan)

usa_citation_plot <- 
ggplot(data = tab_all_citation, aes(x = continent, y = usa.citation.prop)) +
  geom_violin() +
  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = 0.5) +
  stat_summary(fun = "mean",
               geom = "crossbar", 
               width = 0.3,
               colour = "blue") +
  scale_y_continuous(limits = c(0, 1), trans = "sqrt") +
  ylab("Proportion of citations USA-CAN") +
  xlab("Region") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1)) +
  annotate("text", x = 6, y = 1, 
           label = glue::glue("italic(J)=={round(J_usa, 3)}"), 
           parse = TRUE, size = 5)

la_citation_plot <- 
ggplot(data = tab_all_citation, aes(x = continent, y = LA.citation.prop)) +
  geom_violin() +
  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = 0.5) +
  stat_summary(fun = "mean",
               geom = "crossbar", 
               width = 0.3,
               colour = "blue") +
  ylab("Proportion of citations LA") +
  xlab("Region") +
  scale_y_continuous(limits = c(0, 1), trans = "sqrt") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1)) +
  annotate("text", x = 6, y = 1, 
           label = glue::glue("italic(J)=={round(J_la, 3)}"), 
           parse = TRUE, size = 5)

eu_citation_plot <- 
  ggplot(data = tab_all_citation, aes(x = continent, y = eu.citation.prop)) +
    geom_violin() + 
  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = 0.5) +
  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = 0.5) +
  stat_summary(fun = "mean",
               geom = "crossbar", 
               width = 0.3,
               colour = "blue") +
  ylab("Proportion of citations EU") +
  xlab("Region") +
  scale_y_continuous(limits = c(0, 1), trans = "sqrt") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1)) +
  annotate("text", x = 6, y = 1, 
           label = glue::glue("italic(J)=={round(J_eu, 3)}"), 
           parse = TRUE, size = 5)

eastasia_citation_plot <- 
  ggplot(data = tab_all_citation, aes(x = continent, y = EastAsia.citation.prop)) +
    geom_violin() + 
  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = 0.5) +
  geom_dotplot(binaxis = 'y', stackdir = 'center', dotsize = 0.5) +
  stat_summary(fun = "mean",
               geom = "crossbar", 
               width = 0.3,
               colour = "blue") +
  ylab("Proportion of citations East Asia") +
  xlab("Region") +
  scale_y_continuous(limits = c(0, 1), trans = "sqrt") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 75, vjust = 1, hjust = 1)) +
  annotate("text", x = 6, y = 1, 
           label = glue::glue("italic(J)=={round(J_east_asia, 3)}"), 
           parse = TRUE, size = 5)


plot_all <- plot_grid(usa_citation_plot, la_citation_plot, eu_citation_plot, eastasia_citation_plot, ncol = 4)


```

saving plot

```{r}

ggsave(filename = here::here("output", "Fig1_citation_all.png"), 
       plot = plot_all, 
       width = 15, 
       height = 8, 
       dpi = 300)
```




